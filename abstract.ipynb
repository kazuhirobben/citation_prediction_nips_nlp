{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "Our goal here is to create the dictionary of `Keywords_mapping_abstarct`, we go over the papers in the training set. For each paper, we first find the set of keywords (see below for the details of finding the keywords) of the abstract. Let’s say the normalized citations for this paper is $x$ and the abstract of this paper has $n$ keywords. Then, we update the `keyword_score` for each keyword of the abstract of this paper by adding $\\frac{x}{n}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import rake\n",
    "import nltk\n",
    "import unicodedata\n",
    "import operator\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "def abstract_preprocess(text):\n",
    "    if type(text) == float:\n",
    "        text = 'a'\n",
    "    if '\\\\xc2\\\\xa0\\\\xe2\\\\x80\\\\xa6' in text:\n",
    "        text = text.replace(\"\\\\xc2\\\\xa0\\\\xe2\\\\x80\\\\xa6\", '')\n",
    "    text = text.replace('\"','').replace('“','').replace('”','').replace('“','').replace('”','')\n",
    "    \n",
    "    text2 = unicode(text, \"utf8\")  \n",
    "    text = unicodedata.normalize('NFKD',text2).encode('ascii','ignore') \n",
    "    \n",
    "    text_stripped_lower = text.strip().lower()\n",
    "    return text_stripped_lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting keywords:\n",
    "\n",
    "The critical part of this task would be the way that we extract the keywords. To extract the keywords, form abstract, we use three different methods: \n",
    "* NLTK library, \n",
    "* TextBlob library, \n",
    "* RAKE (rapid automatic keyword extraction) algorithm. \n",
    "\n",
    "Following, we describe how the keywords are extracted in each of the mentioned techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract keywords based on  NLTK library\n",
    "\n",
    "Natural Language Toolkit or NLTK is one of the most suitable and well known natural language processing libraries in the Python programming language. We already get familiar with this library throughout the assignments in this semester. One of the simplest ideas for keyword extraction is just looking at the nouns in the abstract. To do so, we first break the abstract into sentences. Then we use Python’s NLTK library features for sentence tokenizing and POS tagging. In this way, we would have tokens and their tags for each sentence in the abstract. The list of POS tags is as follow:\n",
    "\n",
    "* CC coordinating conjunction\n",
    "* CD cardinal digit\n",
    "* DT determiner\n",
    "* EX existential there (like: “there is” … think of it like “there exists”)\n",
    "* FW foreign word\n",
    "* IN preposition/subordinating conjunction\n",
    "* JJ adjective ‘big’\n",
    "* JJR adjective, comparative ‘bigger’\n",
    "* JJS adjective, superlative ‘biggest’\n",
    "* LS list marker 1)\n",
    "* MD modal could, will\n",
    "* NN noun, singular ‘desk’\n",
    "* NNS noun plural ‘desks’\n",
    "* NNP proper noun, singular ‘Harrison’\n",
    "* NNPS proper noun, plural ‘Americans’\n",
    "* PDT predeterminer ‘all the kids’\n",
    "* POS possessive ending parent’s\n",
    "* PRP personal pronoun I, he, she\n",
    "* PRP\\$ possessive pronoun my, his, hers\n",
    "* RB adverb very, silently,\n",
    "* RBR adverb, comparative better\n",
    "* RBS adverb, superlative best\n",
    "* RP particle give up\n",
    "* TO, to go ‘to’ the store.\n",
    "* UH interjection, errrrrrrrm\n",
    "* VB verb, base form take\n",
    "* VBD verb, past tense took\n",
    "* VBG verb, gerund/present participle taking\n",
    "* VBN verb, past participle taken\n",
    "* VBP verb, sing. present, non-3d take\n",
    "* VBZ verb, 3rd person sing. present takes\n",
    "* WDT wh-determiner which\n",
    "* WP wh-pronoun who, what\n",
    "* WP\\$ possessive wh-pronoun whose\n",
    "* WRB wh-abverb where, when\n",
    "\n",
    "\n",
    "Among these tags we choose “nouns” as the keywords of that sentence. Intuitively, it makes more sense that the keywords are from the nouns in compare with verbs, adjectives, conjunctions, etc. \n",
    "\n",
    "Below is the written function for the keyword extraction using NLTK’s tokenizer and POS tager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keywords_nltk(pure_text):\n",
    "    sentences = nltk.sent_tokenize(pure_text) #tokenize sentences\n",
    "    nouns = []  # empty to array to hold all nouns\n",
    "    for sentence in sentences:\n",
    "        for word, pos in nltk.pos_tag(nltk.word_tokenize(str(sentence))):\n",
    "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'):\n",
    "                nouns.append(word)\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we input an abstract to this function, the result would be as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coordinate', 'descent', 'CD', 'method', 'optimization', 'algorithm', 'revival', 'interest', 'performance', 'machine', 'learning', 'applications', 'number', 'papers', 'convergence', 'rate', 'estimates', 'variants', 'selection', 'coordinates', 'estimates', 'descent', 'RCD', 'descent', 'CCD', 'experiments', 'justification', 'comparison', 'paper', 'examples', 'problem', 'classes', 'CCD', 'CD', 'order', 'RCD', 'terms', 'convergence', 'bounds', 'amount', 'improvement', 'rate', 'CCD', 'RCD', 'order', 'characterization', 'order', 'improvement', 'convergence', 'rate', 'terms', 'properties', 'Hessian', 'matrix', 'function']\n"
     ]
    }
   ],
   "source": [
    "keywords = keywords_nltk('The coordinate descent (CD) method is a classical optimization algorithm that has seen a revival of interest because of its competitive performance in machine learning applications. A number of recent papers provided convergence rate estimates for their deterministic (cyclic) and randomized variants that differ in the selection of update coordinates. These estimates suggest randomized coordinate descent (RCD) performs better than cyclic coordinate descent (CCD), although numerical experiments do not provide clear justification for this comparison. In this paper, we provide examples and more generally problem classes for which CCD (or CD with any deterministic order) is faster than RCD in terms of asymptotic worst-case convergence. Furthermore, we provide lower and upper bounds on the amount of improvement on the rate of CCD relative to RCD, which depends on the deterministic order used. We also provide a characterization of the best deterministic order (that leads to the maximum improvement in convergence rate) in terms of the combinatorial properties of the Hessian matrix of the objective function.')\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract keywords based on TextBlob library\n",
    "\n",
    "TextBlob is another library in python that can be used for text processing. It is relatively new python NLP toolkit, which stands on the shoulders of giants like NLTK and Pattern, provides text mining, text analysis and text processing modules for python developers. It provides a simple API for diving into common NLP tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more. Similar idea of POS tagging and noun extraction as the keywords is also implemented using TextBlob library. \n",
    "\n",
    "Following you can see the written function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keywords_textblob(pure_text):\n",
    "    keywords = [w for (w, pos) in TextBlob(pure_text).pos_tags if pos[0] == 'N']\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the result if we input the same abstract to this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coordinate', 'descent', 'CD', 'method', 'optimization', 'algorithm', 'revival', 'interest', 'performance', 'machine', 'learning', 'applications', 'number', 'papers', 'convergence', 'rate', 'estimates', 'variants', 'selection', 'coordinates', 'estimates', 'descent', 'RCD', 'descent', 'CCD', 'experiments', 'justification', 'comparison', 'paper', 'examples', 'problem', 'classes', 'CCD', 'CD', 'order', 'RCD', 'terms', 'convergence', 'bounds', 'amount', 'improvement', 'rate', 'CCD', 'RCD', 'order', 'characterization', 'order', 'improvement', 'convergence', 'rate', 'terms', 'properties', 'Hessian', 'matrix', 'function']\n"
     ]
    }
   ],
   "source": [
    "keywords = keywords_textblob('The coordinate descent (CD) method is a classical optimization algorithm that has seen a revival of interest because of its competitive performance in machine learning applications. A number of recent papers provided convergence rate estimates for their deterministic (cyclic) and randomized variants that differ in the selection of update coordinates. These estimates suggest randomized coordinate descent (RCD) performs better than cyclic coordinate descent (CCD), although numerical experiments do not provide clear justification for this comparison. In this paper, we provide examples and more generally problem classes for which CCD (or CD with any deterministic order) is faster than RCD in terms of asymptotic worst-case convergence. Furthermore, we provide lower and upper bounds on the amount of improvement on the rate of CCD relative to RCD, which depends on the deterministic order used. We also provide a characterization of the best deterministic order (that leads to the maximum improvement in convergence rate) in terms of the combinatorial properties of the Hessian matrix of the objective function.')\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the extracted keywords are same as the keywords as what we extracted from NLTK library. This result is actually expected because we used the same method of “noun” extraction with different library to verify the result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract keywords based on RAKE algorithm\n",
    "Another technique for keyword extraction is using an algorithm called RAKE which is an acronym for Rapid Automatic Keyword Extraction. This algorithm has three main components:\n",
    "* Candidate selection: in this stage all potential keywords including nouns, phrases, terms, concepts, etc.  are selected.\n",
    "* Properties calculation: For each candidate, some properties are calculated that show a potential candidate might be a keyword. For example, if a word occurs a few times in the abstract, it might be a keyword. Also, it is important how many times that word co-occurs with other words.\n",
    "* Scoring and selecting keywords: all candidates can be scored by combining the mentioned properties into a formula. \n",
    "\n",
    "Then, a score or probability threshold is used to select final keywords. \n",
    "\n",
    "Following you can see the function that is used for keyword extraction using RAKE algorithm. As it is explained in the comments, there are three main values that should be identified. The minimum number of characters, the maximum number of words per phrase, and the frequency of the word in the abstract. The “SmartStoplist” is a list of words that can be used to split text into important and unimportant words. For example, “the”, “after”, “at”, “again”, etc. cannot be keyword and they couldn’t be important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keywords_rake(pure_text):\n",
    "    rake_object = rake.Rake(\"SmartStoplist.txt\", 3, 4, 2)\n",
    "    # Each word has at least 3 characters\n",
    "    # Each phrase has at most 4 words\n",
    "    # Each keyword appears in the text at least 2 times\n",
    "    keywords_score = rake_object.run(pure_text)\n",
    "    keywords = [i[0] for i in keywords_score]\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the output of this function for the same input abstract:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deterministic order', 'ccd', 'rcd', 'terms']\n"
     ]
    }
   ],
   "source": [
    "keywords = keywords_rake('The coordinate descent (CD) method is a classical optimization algorithm that has seen a revival of interest because of its competitive performance in machine learning applications. A number of recent papers provided convergence rate estimates for their deterministic (cyclic) and randomized variants that differ in the selection of update coordinates. These estimates suggest randomized coordinate descent (RCD) performs better than cyclic coordinate descent (CCD), although numerical experiments do not provide clear justification for this comparison. In this paper, we provide examples and more generally problem classes for which CCD (or CD with any deterministic order) is faster than RCD in terms of asymptotic worst-case convergence. Furthermore, we provide lower and upper bounds on the amount of improvement on the rate of CCD relative to RCD, which depends on the deterministic order used. We also provide a characterization of the best deterministic order (that leads to the maximum improvement in convergence rate) in terms of the combinatorial properties of the Hessian matrix of the objective function.')\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selected keywords using RAKE algorithm looks more reasonable rather than just “noun” selection. Firstly, it contains multiple-word phrases that could really be a key concept in the paper. Moreover, from the selected keywords, i.e., “CCD (cyclic coordinate descent)” and “RCD (randomized coordinate descent)” we can have the intuition that the keywords are selected more smartly. To summarize, RAKE is a simple keyword extraction library which focuses on finding multi-word phrases containing frequent words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of this notebook, we choose NLTK library ($mode=1$). For TextBlob library, use $mode = 2$ and for RAKE algorithm, use $mode=3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mode = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dictionary of keywords and their scores for training and test datesets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>citations</th>\n",
       "      <th>year</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>citations_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>1987</td>\n",
       "      <td>Inverse matrix calculation can be considered a...</td>\n",
       "      <td>2.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>In the visual cortex of the monkey the horizon...</td>\n",
       "      <td>0.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>1987</td>\n",
       "      <td>The study of distributed memory systems has pr...</td>\n",
       "      <td>1.451613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1987</td>\n",
       "      <td>A lightness algorithm that separates surface r...</td>\n",
       "      <td>0.709677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>The interaction of a set of tropisms is suffic...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  citations  year                                           Abstract  \\\n",
       "0      0         87  1987  Inverse matrix calculation can be considered a...   \n",
       "1      3          5  1987  In the visual cortex of the monkey the horizon...   \n",
       "2      4         45  1987  The study of distributed memory systems has pr...   \n",
       "3      6         22  1987  A lightness algorithm that separates surface r...   \n",
       "4      8          0  1987  The interaction of a set of tropisms is suffic...   \n",
       "\n",
       "   citations_average  \n",
       "0           2.806452  \n",
       "1           0.161290  \n",
       "2           1.451613  \n",
       "3           0.709677  \n",
       "4           0.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./data/data_processed/Abstract_training.csv\")\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4368)\n",
      "(500, 4368)\n",
      "(1000, 4368)\n",
      "(1500, 4368)\n",
      "(2000, 4368)\n",
      "(2500, 4368)\n",
      "(3000, 4368)\n",
      "(3500, 4368)\n",
      "(4000, 4368)\n"
     ]
    }
   ],
   "source": [
    "dic_keywords = {}  # \"keyword : citation\"\n",
    "\n",
    "for i in range(0,len(df_train)):\n",
    "    if i % 500 == 0:\n",
    "        print(i,len(df_train))\n",
    "    text = df_train.Abstract[i]\n",
    "    pure_text = abstract_preprocess(text)\n",
    "    if mode ==1:\n",
    "        keywords = keywords_nltk(pure_text) # Extracting keywords with NLTK POS and picking nouns\n",
    "    elif mode ==2:\n",
    "        keywords = keywords_textblob(pure_text)  # Extracting keywords with TextBlob and picking nouns\n",
    "    elif mode ==3:\n",
    "        keywords = keywords_rake(pure_text)  # Extracting keywords with RAKE algorithm\n",
    "    else:\n",
    "        print('Wrong mode!!!')\n",
    "    \n",
    "    N = len(keywords)\n",
    "    for word in keywords:\n",
    "        if word in dic_keywords.keys():\n",
    "            dic_keywords[word] = dic_keywords[word] + df_train.citations_average[i]/N\n",
    "        else:\n",
    "            dic_keywords[word] = df_train.citations_average[i]/N\n",
    "\n",
    "if mode ==1:    \n",
    "    with open('./data/data_processed/json/dic_keywords_nltk.json', 'w') as fp:\n",
    "        json.dump(dic_keywords, fp)\n",
    "elif mode ==2:    \n",
    "    with open('./data/data_processed/json/dic_keywords_textblob.json', 'w') as fp:\n",
    "        json.dump(dic_keywords, fp)\n",
    "elif mode ==3:    \n",
    "    with open('./data/data_processed/json/dic_keywords_rake.json', 'w') as fp:\n",
    "        json.dump(dic_keywords, fp)      \n",
    "else:\n",
    "        print('Wrong mode!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score calculation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(dic_keywords, my_string, mode):\n",
    "\n",
    "    pure_text = abstract_preprocess(my_string)\n",
    "    if mode ==1:\n",
    "        keywords = keywords_nltk(pure_text) # Extracting keywords with NLTK POS and picking nouns\n",
    "    elif mode ==2:\n",
    "        keywords = keywords_textblob(pure_text)  # Extracting keywords with TextBlob and picking nouns\n",
    "    elif mode ==3:\n",
    "        keywords = keywords_rake(pure_text)  # Extracting keywords with RAKE algorithm\n",
    "    else:\n",
    "        print('Wrong mode!!!')\n",
    "\n",
    "    N = 0 # number of extracted keywords form abstract\n",
    "    score = 0\n",
    "    for word in keywords:\n",
    "        if word in dic_keywords.keys():\n",
    "            score += dic_keywords[word]\n",
    "            N += 1\n",
    "\n",
    "    if score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return score/N #averaging over number of keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if mode == 1:\n",
    "    with open('./data/data_processed/json/dic_keywords_nltk.json') as f:\n",
    "        data_dict = json.load(f)\n",
    "elif mode == 2:\n",
    "     with open('./data/data_processed/json/dic_keywords_textblob.json') as f:\n",
    "        data_dict = json.load(f)\n",
    "elif mode == 3:\n",
    "     with open('./data/data_processed/json/dic_keywords_rake.json') as f:\n",
    "        data_dict = json.load(f)\n",
    "else:\n",
    "    print('Wrong mode!!!')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we find the top-10 keywords of the abstract sorted based on their `keyword_score`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_column</th>\n",
       "      <th>second_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td>model</td>\n",
       "      <td>1290.779605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>data</td>\n",
       "      <td>1056.789386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>networks</td>\n",
       "      <td>916.788576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>paper</td>\n",
       "      <td>761.949494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>learning</td>\n",
       "      <td>754.168289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4348</th>\n",
       "      <td>problem</td>\n",
       "      <td>669.091707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>method</td>\n",
       "      <td>667.055361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>models</td>\n",
       "      <td>646.804264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>network</td>\n",
       "      <td>532.958951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>algorithm</td>\n",
       "      <td>500.291176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     first_column  second_column\n",
       "7819        model    1290.779605\n",
       "684          data    1056.789386\n",
       "5924     networks     916.788576\n",
       "1240        paper     761.949494\n",
       "3231     learning     754.168289\n",
       "4348      problem     669.091707\n",
       "1158       method     667.055361\n",
       "540        models     646.804264\n",
       "2438      network     532.958951\n",
       "1666    algorithm     500.291176"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_x = sorted(data_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'first_column': data_dict.keys(),\n",
    "     'second_column': data_dict.values()\n",
    "    })\n",
    "df.sort_values(['second_column'], ascending=[0])[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_column</th>\n",
       "      <th>second_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td>model</td>\n",
       "      <td>1290.779605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>data</td>\n",
       "      <td>1056.789386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>networks</td>\n",
       "      <td>916.788576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>paper</td>\n",
       "      <td>761.949494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>learning</td>\n",
       "      <td>754.168289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4348</th>\n",
       "      <td>problem</td>\n",
       "      <td>669.091707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>method</td>\n",
       "      <td>667.055361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>models</td>\n",
       "      <td>646.804264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>network</td>\n",
       "      <td>532.958951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>algorithm</td>\n",
       "      <td>500.291176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     first_column  second_column\n",
       "7819        model    1290.779605\n",
       "684          data    1056.789386\n",
       "5924     networks     916.788576\n",
       "1240        paper     761.949494\n",
       "3231     learning     754.168289\n",
       "4348      problem     669.091707\n",
       "1158       method     667.055361\n",
       "540        models     646.804264\n",
       "2438      network     532.958951\n",
       "1666    algorithm     500.291176"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/data_processed/json/dic_keywords_textblob.json') as f:\n",
    "        data_dict = json.load(f)\n",
    "        \n",
    "sorted_x = sorted(data_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'first_column': data_dict.keys(),\n",
    "     'second_column': data_dict.values()\n",
    "    })\n",
    "df.sort_values(['second_column'], ascending=[0])[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_column</th>\n",
       "      <th>second_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>gram model</td>\n",
       "      <td>2043.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>lda</td>\n",
       "      <td>1553.728431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>gans</td>\n",
       "      <td>813.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>cifar</td>\n",
       "      <td>638.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>problem</td>\n",
       "      <td>571.457244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>approach</td>\n",
       "      <td>403.067781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>nmf</td>\n",
       "      <td>395.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>model</td>\n",
       "      <td>366.437725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>generative adversarial network</td>\n",
       "      <td>336.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>data</td>\n",
       "      <td>310.026527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        first_column  second_column\n",
       "1740                      gram model    2043.400000\n",
       "1688                             lda    1553.728431\n",
       "1874                            gans     813.833333\n",
       "2393                           cifar     638.500000\n",
       "2231                         problem     571.457244\n",
       "367                         approach     403.067781\n",
       "1128                             nmf     395.944444\n",
       "1511                           model     366.437725\n",
       "1414  generative adversarial network     336.000000\n",
       "764                             data     310.026527"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/data_processed/json/dic_keywords_rake.json') as f:\n",
    "        data_dict = json.load(f)\n",
    "        \n",
    "sorted_x = sorted(data_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'first_column': data_dict.keys(),\n",
    "     'second_column': data_dict.values()\n",
    "    })\n",
    "df.sort_values(['second_column'], ascending=[0])[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on training\n",
    "\n",
    "Below we use our extracted keywords to predict citations for the papers in the training set. This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>citations</th>\n",
       "      <th>year</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>citations_average</th>\n",
       "      <th>predicted_citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>1987</td>\n",
       "      <td>Inverse matrix calculation can be considered a...</td>\n",
       "      <td>2.806452</td>\n",
       "      <td>187.447644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1987</td>\n",
       "      <td>In the visual cortex of the monkey the horizon...</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>83.991048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>1987</td>\n",
       "      <td>The study of distributed memory systems has pr...</td>\n",
       "      <td>1.451613</td>\n",
       "      <td>116.162506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1987</td>\n",
       "      <td>A lightness algorithm that separates surface r...</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>136.688660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>The interaction of a set of tropisms is suffic...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.969787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  citations  year                                           Abstract  \\\n",
       "0      0         87  1987  Inverse matrix calculation can be considered a...   \n",
       "1      3          5  1987  In the visual cortex of the monkey the horizon...   \n",
       "2      4         45  1987  The study of distributed memory systems has pr...   \n",
       "3      6         22  1987  A lightness algorithm that separates surface r...   \n",
       "4      8          0  1987  The interaction of a set of tropisms is suffic...   \n",
       "\n",
       "   citations_average  predicted_citations  \n",
       "0           2.806452           187.447644  \n",
       "1           0.161290            83.991048  \n",
       "2           1.451613           116.162506  \n",
       "3           0.709677           136.688660  \n",
       "4           0.000000            61.969787  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['predicted_citations'] = df_train['Abstract'].apply(lambda x: predict(data_dict, x, mode))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate correlation between citations_average and predicted_citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13839492300030556"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.citations_average.corr(df_train.predicted_citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the training data with predicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if mode ==1:\n",
    "    df_train.to_csv('./data/data_processed/Abstract_training_predicted_nltk.csv', index=False)\n",
    "elif mode ==2:\n",
    "    df_train.to_csv('./data/data_processed/Abstract_training_predicted_textblob.csv', index=False)\n",
    "elif mode ==3:\n",
    "    df_train.to_csv('./data/data_processed/Abstract_training_predicted_rake.csv', index=False)\n",
    "else:\n",
    "    print('Wrong mode!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Import the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>citations</th>\n",
       "      <th>year</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>citations_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>1987</td>\n",
       "      <td>Many connectionist learning models are impleme...</td>\n",
       "      <td>3.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Amir F. Atiya (*) and James M. Bower (**)(*) D...</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>1987</td>\n",
       "      <td>This paper generalizes the backpropagation met...</td>\n",
       "      <td>2.129032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>1987</td>\n",
       "      <td>Recognizing patterns with temporal context is ...</td>\n",
       "      <td>2.354839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>252</td>\n",
       "      <td>1987</td>\n",
       "      <td>We propose that the back propagation algorithm...</td>\n",
       "      <td>8.129032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  citations  year                                           Abstract  \\\n",
       "0      1         94  1987  Many connectionist learning models are impleme...   \n",
       "1      2          1  1987  Amir F. Atiya (*) and James M. Bower (**)(*) D...   \n",
       "2      5         66  1987  This paper generalizes the backpropagation met...   \n",
       "3      7         73  1987  Recognizing patterns with temporal context is ...   \n",
       "4      9        252  1987  We propose that the back propagation algorithm...   \n",
       "\n",
       "   citations_average  \n",
       "0           3.032258  \n",
       "1           0.032258  \n",
       "2           2.129032  \n",
       "3           2.354839  \n",
       "4           8.129032  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"./data/data_processed/Abstract_test.csv\")[0:]\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on test\n",
    "Below we use our extracted keywords to predict citations for the papers in the training set. This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['predicted_citations'] = df_test['Abstract'].apply(lambda x: predict(data_dict, x, mode) if(pd.notnull(x)) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>citations</th>\n",
       "      <th>year</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>citations_average</th>\n",
       "      <th>predicted_citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>1987</td>\n",
       "      <td>Many connectionist learning models are impleme...</td>\n",
       "      <td>3.032258</td>\n",
       "      <td>226.145507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Amir F. Atiya (*) and James M. Bower (**)(*) D...</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>42.464439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>1987</td>\n",
       "      <td>This paper generalizes the backpropagation met...</td>\n",
       "      <td>2.129032</td>\n",
       "      <td>308.769021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>1987</td>\n",
       "      <td>Recognizing patterns with temporal context is ...</td>\n",
       "      <td>2.354839</td>\n",
       "      <td>114.649391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>252</td>\n",
       "      <td>1987</td>\n",
       "      <td>We propose that the back propagation algorithm...</td>\n",
       "      <td>8.129032</td>\n",
       "      <td>215.310316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  citations  year                                           Abstract  \\\n",
       "0      1         94  1987  Many connectionist learning models are impleme...   \n",
       "1      2          1  1987  Amir F. Atiya (*) and James M. Bower (**)(*) D...   \n",
       "2      5         66  1987  This paper generalizes the backpropagation met...   \n",
       "3      7         73  1987  Recognizing patterns with temporal context is ...   \n",
       "4      9        252  1987  We propose that the back propagation algorithm...   \n",
       "\n",
       "   citations_average  predicted_citations  \n",
       "0           3.032258           226.145507  \n",
       "1           0.032258            42.464439  \n",
       "2           2.129032           308.769021  \n",
       "3           2.354839           114.649391  \n",
       "4           8.129032           215.310316  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate correlation between citations_average and predicted_citations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.051434255802564804"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.citations_average.corr(df_test.predicted_citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the test data with predicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if mode ==1:\n",
    "    df_test.to_csv('./data/data_processed/Abstract_test_predicted_nltk.csv', index=False)\n",
    "elif mode ==2:\n",
    "    df_test.to_csv('./data/data_processed/Abstract_test_predicted_textblob.csv', index=False)\n",
    "elif mode ==3:\n",
    "    df_test.to_csv('./data/data_processed/Abstract_test_predicted_rake.csv', index=False)\n",
    "else:\n",
    "    print('Wrong mode!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
