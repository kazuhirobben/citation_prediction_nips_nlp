{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affiliation\n",
    "\n",
    "In order to create the dictionary of `Affiliations_mapping`, we go over the papers in the training set. For each paper and for each affiliation of this paper (see below for the details of extracting “clean” affiliations), we add the normalized citations (that is, the average number of citations per year) for this paper to the `affiliation_score` for this affiliation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import unicodedata\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "import json\n",
    "\n",
    "UNIVERSITIES = {'UCSD': 'University of California, San Diego', 'USC': 'University of Southern California',\n",
    "                'UCLA': 'University of California, Los Angeles', 'MIT': 'Massachusetts Institute of Technology', \n",
    "                'UC Montreal': 'University of Montreal', 'Caltech': 'California Institute of Technology',\n",
    "                'UCSB': 'University of California, Santa Barbara', 'NYU': 'New York University',\n",
    "                'UCI': 'University of California, Irvine', 'JPL': 'Jet Propulsion Laboratory',\n",
    "                'Georgia Tech': 'Georgia Institute of Technology',\n",
    "                'CMU': 'Carnegie Mellon University', 'Oxford': 'University of Oxford',\n",
    "                'Berkeley': 'University of California, Berkeley', 'Stanford': 'Stanford University'\n",
    "}\n",
    "\n",
    "NLP = en_core_web_sm.load()\n",
    "\n",
    "USER_DEFINED_STOP_WORDS = ['Computer Science', 'Electrical Engineering','Faculty', 'Professor', 'Founder', 'CEO', \n",
    "                           'Emeritus', 'Postdoctoral Research Fellow', 'EECS', 'Statistics', 'Economics', 'Physics',\n",
    "                          \"Research scientist\", \"Associate Professor\", \"Assistant Professor\", \"Marketing\", \n",
    "                           \"Postdoctoral Researcher\", \"Psychology\", \"Biology\", \"ECE\", \"CS\", \"Industrial Engineering\", \"ISE\", \n",
    "                           \"Research Staff\", \"Inc\", 'Engineering', 'Biomedical', \"Signal\", \"Processing\", 'Information',\n",
    "                          \"Data Sciences\", \"PhD\", \"Student\", \"Physicist\", \"Mechanical\", \"Consultant\", \"Organizational Behavior\",\n",
    "                          \"Pure Mathematics\", \"Bioinformatics\", 'Department', 'Medical', 'School', 'Biochemistry', \n",
    "                           'Technical Staff', 'Genomics',\"Statistical Sciences\"] \n",
    "\n",
    "ENGLISH_STOP = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "STOP_WORDS = set(list(string.punctuation))\n",
    "STOP_WORDS.remove(',')\n",
    "\n",
    "SPECIAL_ORG = ['Google', 'Facebook', 'Apple', 'CNRS', 'Stanford', 'Microsoft', 'IBM', 'NVIDIA', 'Yahoo', 'Adobe', 'Xerox', 'Nokia', 'Samsung', \n",
    "              'Simons', 'Berkeley', 'Stanford', 'Princeton', 'Oxford', 'ETH Zurich', 'Uber', 'Lyft', 'OpenAI'] + UNIVERSITIES.keys()\n",
    "\n",
    "CURRENT_YEAR = 2018\n",
    "\n",
    "class MyDF(object):\n",
    "    \n",
    "    def __init__(self, path, name):\n",
    "        self.name = name\n",
    "        self.df = pd.read_csv(path)\n",
    "        self.df_orig = self.df.copy()\n",
    "        self.drop_redundant_columns()\n",
    "        self.max_num_names = len(self.df.columns) -1\n",
    "        self.make_all_object()\n",
    "        self.num_non_nan = self.count_non_nan()\n",
    "        self.list_unique_non_nan = self.list_unique_non_nan()\n",
    "        self.num_unique_non_nan = len(self.list_unique_non_nan)\n",
    "    \n",
    "    def drop_redundant_columns(self):\n",
    "        self.df = self.df.drop('year', axis=1)\n",
    "        self.df = self.df.drop('index', axis=1)\n",
    "        self.df = self.df.drop('citations', axis=1)\n",
    "        \n",
    "    def make_all_object(self):\n",
    "        for i in range(0,self.max_num_names):\n",
    "            self.df[self.name + '{x}'.format(x=i)] = self.df[self.name + '{x}'.format(x=i)].astype(object)\n",
    "        \n",
    "    def list_unique_non_nan(self):\n",
    "        return pd.concat([self.df[self.name + '{x}'.format(x=i)] for i in range(0,self.max_num_names) ]).dropna().unique().tolist()\n",
    "    \n",
    "    def count_non_nan(self):\n",
    "        return pd.concat([self.df[self.name + '{x}'.format(x=i)] for i in range(0,self.max_num_names) ]).dropna().count()\n",
    "       \n",
    "    def making_name_score_df(self):\n",
    "        df_copy = self.df.copy()\n",
    "        # keep index as index, stack other columns 'against' it\n",
    "        stacked = df_copy.set_index('citations_average').stack()\n",
    "        # set the name of the new series created\n",
    "        df_temp = stacked.reset_index(name=self.name)\n",
    "        # drop the 'source' level (key.*)\n",
    "        df_temp.drop('level_1', axis=1, inplace=True)\n",
    "        \n",
    "        unique_names = df_temp[self.name].unique()\n",
    "        names_score = []\n",
    "        for name in unique_names:\n",
    "            names_score.append(df_temp.loc[df_temp[self.name] == name]['citations_average'].sum())\n",
    "        \n",
    "        table = [unique_names, names_score]\n",
    "        output_df = pd.DataFrame(table)\n",
    "        output_df = output_df.transpose()\n",
    "        output_df.columns=[self.name, 'Score']\n",
    "        \n",
    "        output_dict = dict(zip(unique_names, names_score))\n",
    "        \n",
    "        return [output_df, output_dict]\n",
    "    \n",
    "    def polish_data(self, target):\n",
    "        \n",
    "        df_processed = self.df\n",
    "        for n in self.list_unique_non_nan:\n",
    "            score = target.loc[target[self.name] == n]['Score'].sum()\n",
    "            df_processed = df_processed.replace(n, score)\n",
    "            \n",
    "        df_processed['predicted_citations']= df_processed.iloc[:, 2:self.max_num_names+2].sum(axis=1)\n",
    "        return df_processed\n",
    "    \n",
    "    def find_best_ORG(self, aff):\n",
    "        \n",
    "        for org in SPECIAL_ORG:\n",
    "            if org in aff:\n",
    "                return org\n",
    "        \n",
    "        text = unicode(aff,\"utf-8\")\n",
    "        doc = NLP(text)\n",
    "        texts = []\n",
    "        lengths = []\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == u\"ORG\":\n",
    "                texts.append(ent.text)\n",
    "                lengths.append(ent.end_char - ent.start_char)\n",
    "        if len(texts) >0:\n",
    "            return texts[lengths.index(max(lengths))]\n",
    "        else:\n",
    "            return ''\n",
    "        \n",
    "    def strip_affiliation(self, x):\n",
    "        # replace abbreviations\n",
    "        x = x.replace('Univ.', \"University\")\n",
    "        x = x.replace('U.', \"University of\")\n",
    "        decoded = x.decode('string_escape')\n",
    "        text = unicode(decoded, 'utf8', errors='ignore')\n",
    "        x1 = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore') \n",
    "        x1 = x1.strip()\n",
    "        for name in USER_DEFINED_STOP_WORDS:\n",
    "            x1 = x1.replace(name, '')\n",
    "        return x1.strip()\n",
    "    \n",
    "    def map_abbr(self, x):\n",
    "        try:\n",
    "            y = UNIVERSITIES[x]\n",
    "            return y\n",
    "        except KeyError:\n",
    "            return x\n",
    "    \n",
    "    def remove_punctuations(self, x):\n",
    "        \n",
    "        x1 = [w for w in x.split() if w not in set(STOP_WORDS)]  # remove stopwords\n",
    "        if len(x1) > 1:\n",
    "            if x1[0] in ENGLISH_STOP:\n",
    "                del x1[0]\n",
    "        if len(x1) > 1:        \n",
    "            if x1[-1] in ENGLISH_STOP:\n",
    "                del x1[-1]\n",
    "        return ' '.join(x1).strip()                                     # join the list\n",
    "    \n",
    "    def polish_affiliations(self):\n",
    "        \n",
    "        polished_affiliations = []\n",
    "        for aff in self.list_unique_non_nan:\n",
    "            stripped_affiliation = self.strip_affiliation(aff)\n",
    "            recognized_affiliation = self.find_best_ORG(stripped_affiliation)\n",
    "            semi_polished_affiliation = self.remove_punctuations(recognized_affiliation)\n",
    "            polished_affiliation = self.map_abbr(semi_polished_affiliation)\n",
    "            if polished_affiliation != \"\":\n",
    "                polished_affiliations.append(polished_affiliation)\n",
    "            else:\n",
    "                polished_affiliations.append(np.nan)\n",
    "            \n",
    "        self.df = self.df.replace(self.list_unique_non_nan, polished_affiliations)\n",
    "        \n",
    "        self.list_unique_non_nan = list(set(polished_affiliations))\n",
    "        self.num_unique_non_nan = len(self.list_unique_non_nan)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting clean affiliations: \n",
    "\n",
    "The way we obtained the affiliation for each author was using the google scholar of this author (if exists). However, in the google scholar page of authors, usually there exists extra information in the affiliation part and authors describe their position (Faculty, Professor, Assistant Professor, Associate Professor, Researcher, Student, Post-doc, …), the department they are in (Electrical Engineering, Computer Science, …), and finally the name of the organization they are in.\n",
    "\n",
    "There are total number of 1102 unique affiliations in our training set.\n",
    "\n",
    "In order to extract the correct affiliation names, what we have done is as follows: for each affiliation string s we obtained from google scholar,\n",
    "\n",
    "1-\tWe removed any word in this string that matches the following list of positions or department names:\n",
    "\n",
    "['Computer Science', 'Electrical Engineering', 'Faculty', 'Professor', 'Founder', 'CEO', 'Emeritus', 'Postdoctoral Research Fellow', 'EECS', 'Statistics', 'Economics', 'Physics', \"Research scientist\", \"Associate Professor\", \"Assistant Professor\", \"Marketing\", \"Postdoctoral Researcher\", \"Psychology\", \"Biology\", \"ECE\", \"CS\", \"Industrial Engineering\", \"ISE\", \"Research Staff\", \"Inc\", 'Engineering', 'Biomedical', \"Signal\", \"Processing\", 'Information', \"Data Sciences\", \"PhD\", \"Student\", \"Physicist\", \"Mechanical\", \"Consultant\", \"Organizational Behavior\", \"Pure Mathematics\", \"Bioinformatics\", 'Department', 'Medical', 'School', 'Biochemistry', 'Technical Staff', 'Genomics']\n",
    "\n",
    "2-\tWe replaced “U.“ with “University of” and “Univ.” with “University” in the string s.\n",
    "3-\tSome organizations appeared with different names in our dataset obtained from google scholar. For example, we had Google, Google Brain, Google Deepmind, Google AI, … We created the following list of special organizations: \n",
    "\n",
    "['Google', 'Facebook', 'Apple', 'CNRS', 'Stanford', 'Microsoft', 'IBM', 'NVIDIA', 'Yahoo', 'Adobe', 'Xerox', 'Nokia', 'Samsung', 'Simons', 'Berkeley', 'Stanford', 'Princeton', 'Oxford', 'ETH Zurich', 'Uber', 'Lyft', 'OpenAI']\n",
    "\n",
    "and if any name in this list exists as a word in string s, we consider that word as the organization for string s.\n",
    "\n",
    "4-\tSome organizations appeared with their abbreviations in our dataset obtained from google scholar. For example, we had ‘MIT’ instead of ‘Massachusetts Institute of Technology’, ‘USC’ instead of ‘University of Southern California’, …. We created the following dictionary with universities’ abbreviations at the keys and the full name of these organizations as values:\n",
    "\n",
    "{'UCSD': 'University of California, San Diego', 'USC': 'University of Southern California', 'UCLA': 'University of California, Los Angeles', 'MIT': 'Massachusetts Institute of Technology',  'UC Montreal': 'University of Montreal', 'Caltech': 'California Institute of Technology', 'UCSB': 'University of California, Santa Barbara', 'NYU': 'New York University', 'UCI': 'University of California, Irvine', 'JPL': 'Jet Propulsion Laboratory', 'Georgia Tech': 'Georgia Institute of Technology', 'CMU': 'Carnegie Mellon University', 'Oxford': 'University of Oxford', 'Berkeley': 'University of California, Berkeley', 'Stanford': 'Stanford University'}\n",
    "\t \n",
    "Now if any of the keys of this dictionary exists as a word in string s, we consider the value for that key as the organization for string s.\n",
    "\n",
    "5-\tWe used named entity recognition (NER) from library Spacy to extract words with label ORG for string s. If there exist more than one word with label ORG, we choose the longest word. \n",
    "\n",
    "In the following, we provide some examples for extracting affiliations from the string we obtained for affiliations of the authors using Google Scholar.\n",
    "\n",
    "Original string: Professor, Computer Science, University of California Irvine \n",
    "Extracted affiliation: University of California Irvine\n",
    "\n",
    "Original string: Professor Emeritus, School of ECE & Dept. of Statistical Sciences, Cornell University \n",
    "Extracted affiliation: Cornell University\n",
    "\n",
    "Original string: Google Research, NY \n",
    "Extracted affiliation: Google\n",
    "\n",
    "Original string: Professor of Psychology, Co-Director of Princeton Neuroscience Institute, Princeton \n",
    "Extracted affiliation: Princeton\n",
    "\n",
    "Original string: Professor MIT \n",
    "Extracted affiliation: Massachusetts Institute of Technology\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataframe of affiliations and their scores for all affiliations in the training set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mohammad/anaconda/lib/python2.7/site-packages/pandas/core/missing.py:51: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  mask = arr == x\n"
     ]
    }
   ],
   "source": [
    "df_affiliation_training = MyDF(\"./data/data_processed/Affiliation_training.csv\", \"Affiliation\")\n",
    "df_affiliation_training.polish_affiliations()\n",
    "[df_affiliation_score, dict_affiliation_score] = df_affiliation_training.making_name_score_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./data/data_processed/json/Affiliations_score.json\", \"w\") as fp:\n",
    "    json.dump(dict_affiliation_score , fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we indicate the top-10 affiliations sorted based on their author_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Google</td>\n",
       "      <td>14553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>5950.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>OpenAI</td>\n",
       "      <td>4500.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Stanford University</td>\n",
       "      <td>2199.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>2096.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>1817.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>University of California, Berkeley</td>\n",
       "      <td>1530.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>1368.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>University of Oxford</td>\n",
       "      <td>1209.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>University of Montreal</td>\n",
       "      <td>1200.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Affiliation    Score\n",
       "7                                   Google    14553\n",
       "45                                Facebook  5950.87\n",
       "481                                 OpenAI  4500.97\n",
       "68                     Stanford University  2199.47\n",
       "10   Massachusetts Institute of Technology  2096.46\n",
       "89                               Microsoft  1817.68\n",
       "35      University of California, Berkeley  1530.83\n",
       "281                                 NVIDIA  1368.59\n",
       "39                    University of Oxford  1209.49\n",
       "24                  University of Montreal  1200.75"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_affiliation_score.sort_values(['Score'], ascending=[0])[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between citations and score_mean in Training for Affiliations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1532766022380167"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_affiliations_df = df_affiliation_training.polish_data(df_affiliation_score)\n",
    "train_affiliations_df.citations_average.corr(train_affiliations_df.predicted_citations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the training data with predicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_affiliations_df.to_csv('./data/data_processed/Affiliation_training_predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataframe of affiliations and their scores for all affiliations in the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_affiliation_test = MyDF(\"./data/data_processed/Affiliation_test.csv\", \"Affiliation\")\n",
    "df_affiliation_test.polish_affiliations()\n",
    "test_affiliations_df = df_affiliation_test.polish_data(df_affiliation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between citations and score_mean in Test for Affiliation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12052455206648188"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_affiliations_df.citations_average.corr(test_affiliations_df.predicted_citations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the test data with predicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_affiliations_df.to_csv('./data/data_processed/Affiliation_test_predicted.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
